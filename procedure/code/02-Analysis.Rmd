---
output: html_document 
---

# Reproduction of Malcomb et al (2014)

#### Malcomb, D. W., E. A. Weaver, and A. R. Krakowka. 2014. Vulnerability modeling for sub-Saharan Africa: An operationalized approach in Malawi. Applied Geography 48:17-30.

#### [https://doi.org/10.1016/j.apgeog.2014.01.004]([https://doi.org/10.1016/j.apgeog.2014.01.004)

### Authors: Kufre Udoh, Drew An-Pham, Joseph Holler, and Middlebury College Fall 2019 + Spring 2021 Geography 323 Class

### [https://gis4dev.github.io/](https://gis4dev.github.io/)


```{r install packages and load libraries, include = F}
packages = c("downloader", "haven", "stars", "dplyr", "sf", "rdhs", "classInt",
             "readr", "ggplot2", "here", "s2", "pastecs", "cartography")

install.packages(setdiff(packages, rownames(installed.packages())), quietly=TRUE)

library(downloader)
library(haven)
library(sf)
library(stars)
library(dplyr)
library(here)
library(classInt)
library(rdhs)
library(readr)
library(ggplot2)
library(s2)
library(pastecs)
library(cartography)

sf_use_s2(TRUE)
```

```{r save R processing environment}

# save the R processing environment, including date in file name
env <- here("procedure", "environment")
if (!file.exists(here(env, "r_environment.txt"))) {
  writeLines(
    capture.output(sessionInfo()), here(env, "r_environment.txt")
  )
} else {writeLines(
    capture.output(sessionInfo()),
    here(env, paste0("r-environment-", Sys.Date(), ".txt"))
  )
}
```


```{r define raw data paths}
private_r <- here("data","raw","private")
public_r <- here("data","raw","public")
```


```{r load data used for analysis, message=FALSE}
ta_gref <- read_sf(here("data", "derived", "public", "ta_fig4_v.gpkg"), layer = "ta_fig4_v") %>% 
  st_make_valid()
# This read may need to be changed to match the final output of 01-preanalysis!
# which was: st_write(ta_v, here("data", "derived", "public", "ta_v.gpkg"), append=FALSE)

dr <- read_stars(here(public_r, "dr1010ipeykx.tif")) %>% 
  st_set_crs(4326) 

fl <- read_stars(here(public_r,  "fl1010irmt.tif")) %>% 
  st_set_crs(4326) 

lhz_v <- read_sf(here(public_r, "MW_LHZ_2009.shp")) %>% 
  st_make_valid()

lhz_t <- read.csv(here(public_r, "lhz.csv"))

ta <- read_sf(here(public_r, "MWI_adm2.shp")) %>%
  st_make_valid() 

lakes <- read_csv(here(public_r, "major_lakes.csv")) %>% 
  select("name", "the_geom") %>% 
  st_as_sf(wkt = "the_geom", crs = 4326) %>%
  st_geometry %>%
  st_union %>%
  st_sf %>%
  mutate(EA = "Major Lakes of Malawi")
```

```{r load adaptive capacity data}
dhsclusters_2010 <- readRDS(here(private_r, "datasets", "MWGE62FL.rds")) %>%
  as("sf") 
  
dhshh_2010 <- readRDS(here(private_r, "datasets", "MWHR61SV.rds")) %>% 
  zap_labels()
```


```{r join traditional authority and cluster data to households}
# spatial join traditional authority ID to clusters
cluster_ta <- dhsclusters_2010 %>% 
  st_join(ta_gref) %>% 
  st_drop_geometry() %>% 
  select(DHSCLUST, ta_id = ID_2, urban_rural = URBAN_RURA)

# join traditional authority and urban/rural data to DHS surveys
# select variables for adaptive capacity analysis
dhshh_2010 <- dhshh_2010 %>%
  left_join(cluster_ta, by = c("HV001" = "DHSCLUST")) %>% 
  select(HHID,
         HV001,
         HV002,
         ta_id,
         urban_rural,
         HV246A,
         HV246D,
         HV246E,
         HV246G,
         HV248,
         HV245,
         HV271,
         HV251,
         HV204,
         HV206,
         HV226,
         HV219,
         HV243A,
         HV207)

paste(sum(is.na(cluster_ta$ta_id)),
      "clusters did not join to a Traditional Authority, affecting",
      sum(is.na(dhshh_2010$ta_id)),
      "household surveys")

```


```{r households to remove}
# create list of households with inconclusive data for adaptive capacity 
# that is, the household gave a "do not know" answer to a question
rmv_2010 = dhshh_2010 %>%  
  filter(
  HV246A == 98 |
    HV246A == 99 |
    HV246D == 98 |
    HV246D == 99 |
    HV246E == 98 |
    HV246E == 99 |
    HV246G == 98 |
    HV246G == 99 |
    HV219  == 9 |
    HV243A == 9 |
    HV245  == 99 |
    HV206  == 9 |
    HV204  == 999 |
    HV204  == 998 |
    HV226  == 99 |
    HV226  == 95 |
    HV226  == 96 |
    HV207  ==  9 |
    (is.na(HV246A) & is.na(HV246D) & is.na(HV246E) & is.na(HV246G))) 
paste(nrow(rmv_2010), "household surveys with inconclusive attribute data")

```


```{r remove missing data}

paste(nrow(dhshh_2010), "household surveys")
# count missing ta_id's
hh_capacity_t <- dhshh_2010 %>%
  anti_join(rmv_2010, by = "HHID") %>% # 24638 records
  filter(!is.na(ta_id)) # 23543 records
paste(nrow(hh_capacity_t), "household surveys with complete data")
paste(nrow(dhshh_2010)-nrow(hh_capacity_t), "surveys removed for missing data")

```


```{r capacity in households 2010}

hh_capacity_t <- hh_capacity_t %>%
  rowwise() %>%
  mutate(hhlivestock = sum(HV246A, HV246D, HV246E, HV246G, na.rm = T)) %>%
  ungroup() %>% 
  mutate(
    livestock = percent_rank(hhlivestock) * 4,
    sick = percent_rank(desc(HV248)) * 4,
    land = percent_rank(HV245) * 4,
    wealth = percent_rank(HV271) * 4,
    orphans = percent_rank(desc(HV251)) * 4,
    
    # femalehh male = 1, female = 2, run 0 to 1.128 is the binary
    
    HV204 = ifelse(HV204 == 996, 0, HV204), #change 996(water on premise) to 0
    water = percent_rank(desc(HV204)) * 4,
    electricity = percent_rank(HV206) * 4,
    cooking = percent_rank(desc(HV226)) * 4,
    femalehh = percent_rank(desc(HV219)) * 4, # male = 1 and female = 2
    cellphone = percent_rank(desc(HV243A)) * 4,
    radio = percent_rank(HV207) * 4,
    urban_rural = ifelse(urban_rural == "U", 1, 0),
    urbanruralscore = percent_rank(urban_rural) * 4)

    # percent_rank sets values 0 to 1, then * 4 puts everything on a 0-4 scale
    # default is ascending order, with lower values being more vulnerable
    # desc() option inverts order, with higher values being more vulnerable
 
```

```{r capacity for traditional authorities 2010 at the household level}
# calculating capacity scores based on Table 2 in Malcomb et al (2014)
hh_capacity_t <- mutate(hh_capacity_t, 
                        capacity = 
                        0.04 * livestock +
                        0.03 * sick +
                        0.06 * land +
                        0.04 * wealth +
                        0.03 * orphans +
                        0.04 * water +
                        0.03 * electricity +
                        0.02 * cooking +
                        0.02 * femalehh +
                        0.04 * cellphone +
                        0.03 * radio +
                        0.02 * urbanruralscore
                        )
 
```

``` {r summary stats for TAs at household level before pullings nas}
hh_stats <- stat.desc(hh_capacity_t[,21:33]) %>%
  mutate_if(is.numeric, round, digits=1)
hh_stats
```

```{r households with incomplete capacity data}

hh_null <- filter(hh_capacity_t, is.na(capacity))
paste(nrow(hh_null), "household surveys with null data")
hh_null_stats <- stat.desc(hh_null[,21:32]) %>%
  mutate_if(is.numeric, round, digits=1)
hh_null_stats

```

```{r remove incomplete households}
hh_capacity_t <- hh_capacity_t %>%
  
filter(!is.na(capacity)) 
paste(nrow(hh_capacity_t), "household surveys with complete adaptive capacity")

```


``` {r summary statistics for household adaptive capacity}

hh_capacity_stats <- stat.desc(hh_capacity_t[,21:33]) %>%
  mutate_if(is.numeric, round, digits=1)
hh_capacity_stats
paste(nrow(ta_capacity_t),
      "traditional authorities with adaptive capacity data")
```

```{r aggregate adaptive capacity to traditional authorities}

ta_capacity_t <- hh_capacity_t %>% 
  group_by(ta_id) %>%
  summarize(
    capacity_avg = mean(capacity),
    capacity_min = min(capacity),
    capacity_max = max(capacity),
    capacity_sd = sd(capacity))

ta_capacity_t

```


```{r joining 2010 capacity to ta and creating breaks for visualization}
# join mean capacity to traditional authorities
ta_v = left_join(
  ta_gref,
  select(ta_capacity_t, ta_id, capacity_2010 = capacity_avg),
  by = c("ID_2" = "ta_id")
)

# indicators ranged 0-4 and were multiplied by weights totaling 0.4
# yielding maximum theoretical score of 1.6; therefore multiply by 25
# which achieves a maximum score of 40
ta_v = mutate(ta_v, capacity_2010 = capacity_2010 * 25)


# preparing breaks for mapping using natural jenks method
ta_brks = filter(ta_v, !is.na(capacity_2010)) %>% {classIntervals(.$capacity_2010, 4, style = "jenks")$brks}

ta_int = lapply(1:4, function(x) paste0(round(ta_brks[x],2)," - ", round(ta_brks[x +1],2))) %>% unlist()

ta_v = mutate(ta_v, capacity_2010_brks = case_when(
  capacity_2010 <= ta_brks[2] ~ ta_int[1],
  capacity_2010 <= ta_brks[3] ~ ta_int[2],
  capacity_2010 <= ta_brks[4] ~ ta_int[3],
  capacity_2010 >  ta_brks[4] ~ ta_int[4]
))
```



```{r extract traditional authorities without data by capacity, warning=FALSE}
ta_null_cap <- ta_v[is.na(ta_v$capacity_2010),]
#20 features

st_write(ta_null_cap, 
         here("data", "derived", "public", "ta_null_capacity.shp"), 
         append=FALSE,
         quiet = TRUE)
```

```{r saving adaptive capacity scores}
save(
  ta_capacity_t,
  file = here("data", "derived", "public", "adaptive_capacity.rData")
)
```


```{r check final ta_v output before mapping}
ta_v_check <- ggplot() + 
  geom_sf(data = ta_v, aes(fill = capacity_2010), size = .1, color = "grey98") + 
  scale_fill_continuous(
    name = "Adaptive\nCapacity\nScores", 
    low="lemonchiffon1", 
    high="lightcoral", 
    na.value = "snow3") 
ta_v_check 
```

```{r cleaning and reprojecting rasters}
# creating blank raster in extent
# extent of the raster layers
# units used for bounding box = decimal degrees, long-lat
b = st_bbox(
  c(
    xmin = 35.9166666666658188,
    xmax = 32.6666666666658330,
    ymin = -9.3333333333336554,
    ymax = -17.0833333333336270
  ),
  crs = st_crs(4326)
) %>%
  st_as_sfc()

# where raster = 1, you have flood visualized
# alternative resolution: 0.083333
blank = st_as_stars(st_bbox(b), dx = 0.041667, dy = 0.041667)
blank[[1]][] = NA

# warp: convert from one raster grid to another, preserve the dats type you start with
# reprojecting, clipping, and resampling rasters to new extent and cell size
# use bilinear for drought to average continuous population exposure values 
# (object, destination, logical operator, usable b/c of GDAL)
dr = st_warp(dr, blank, use_gdal = T, method = "bilinear")
# use nearest neighbor for flood risk to preserve integer values
fl = st_warp(fl, blank, method = "near")  

# removing factors from fl
# You can use double brackets to select elements in more or less the same way as single brackets. The difference between single and double is that with double brackets any element names are not displayed.
# rasters are a raised matrix (multiple layer) access first level of the array, second bracket editing values into the array
nmrc = as.numeric(levels(fl[[1]]))[fl[[1]]]
fl = blank
# single bracket gives you meta data (first layer), double brackets gives it to you as a matrix
fl[[1]][] = nmrc
```

```{r rasterizing geometries}
# clipping traditional authorities with livelihood zones in order to remove lake and existing null values
# building a clip function in R [x,y are parameters]
st_clip = function(x,y) st_intersection(x, st_union(st_geometry(y)))

st_agr(ta_v) = "constant"

#creates a small buffer around the Livelihood Zones & use this as a mask to clip features from Traditional Authorities (only the TAs that have data clipped to the extent of Malawi)
ta_capacity_v = st_clip(st_transform(filter(ta_v, is.na(capacity_2010) == F), 3395), st_buffer(st_transform(lhz_v, 3395), .01)) %>%
  st_transform(4326)
# 214 features 

# making capacity rasters 
ta_capacity_r = st_rasterize(ta_capacity_v[, 'capacity_2010'], blank)
```


```{R calculate livelihood sensitivity}
# LHZ Data
lhz_sensitivity_v  = lhz_v %>%
  inner_join(lhz_t, by = ("LZCODE" = "LZCODE")) %>%
  mutate(
    pctOwnCrop = (sof_crop + sof_livestock) * 100, 
    pctIncWage = (soc_labour / soc_total) * 100,
    pctIncCashCrops = (cp_tobacco + cp_sugar + cp_tea + cp_coffee) / soc_total 
      * 100,
    pctDisasterCope = (se_firewoord + se_grass	+ se_wildfood + se_charcoal + 
      se_matmaking + se_basket) / soc_total * 100
  ) %>%
  
  mutate(
  ownCrop = percent_rank(pctOwnCrop) * 4, 
  # high ownCrop percentages indicate low sensitivity 
  wageIncome = percent_rank(pctIncWage) * 4, 
  # high wage percentages indicate low sensitivity
  cashCropIncome = percent_rank(desc(pctIncCashCrops)) * 4, 
  # high cash crop percentages indicate high sensitivity (market exposure)
  newDisaster = percent_rank(desc(pctDisasterCope)) * 4, 
  # high disaster coping strategy percentages indicate high sensitivity 
  ) %>%
  mutate(
    sensitivity = (
      0.06 * ownCrop +
      0.06 * wageIncome +
      0.04 * cashCropIncome +
      0.04 * newDisaster
      ) * 25
  )  
# livelihood sensitivity range is 5.88 to 14.00
# making capacity rasters 

lhz_sensitivity_r = st_rasterize(lhz_sensitivity_v[,'sensitivity'], blank)

lhz_v_check <- ggplot() + 
  geom_sf(data = lhz_sensitivity_v, 
          aes(fill = sensitivity), size = .2, color = "grey98") +
  scale_fill_continuous(name = "Livelihood\nSensitivity\nScores", low="lemonchiffon1", high="lightcoral")
lhz_v_check
```

```{r summary table with lhz data}
lhz_stats <- st_drop_geometry(lhz_sensitivity_v[,14:36]) %>%
  stat.desc() %>%
  mutate_if(is.numeric, round, digits=1)
lhz_stats
```

```{r function to calculate vulnerability}
  # creating mask layer
  mask = ta_capacity_r
  mask[mask > 0] = 1
  mask[mask == 0] = NA # one with zero should not be included
  
  # masking flood and drought 
  #reclassify drought & flood already has classification
  #we want flood to have 20% weight so we multiply by 5, as is the data has a range of 0-4
  flood = fl * mask * 5
  drought = dr * mask
  
  # makes a list of quintile break points
  qt = quantile(drought[[1]], probs = seq(0, 1, 0.2), na.rm = T)
  
  # reclassifying drought layer using break points from 0 to 4
  # 4 * 5 = 20, match 20% weighting of exposition to drought events
  drought = drought %>%
    mutate(
      recoded = case_when(
        drought[[1]] <= qt[[2]] ~ 0,
        drought[[1]] <= qt[[3]] ~ 1,
        drought[[1]] <= qt[[4]] ~ 2,
        drought[[1]] <= qt[[5]] ~ 3,
        drought[[1]] > qt[[5]] ~ 4
      )
    ) %>% select(recoded) * 5
  
  # final output (adding component rasters)
  final = 100 - (ta_capacity_r + lhz_sensitivity_r + (40 - (drought + flood))) # 100 = highest vulnerability, 0 = lowest vulnerability
```


```{r descriptive stats for raster inputs}
fl_stats <- stat.desc(fl)
dr_stats <- stat.desc(dr)
fl_stats
dr_stats
```

```{r creating final vulnerability layers}
ta_capacity_v <- st_make_valid(ta_capacity_v) # new version of sf (1.0.0) produces error, so st_make_valid fixes spherical geom errors

ta_capacity_v$vuln = aggregate(final,ta_capacity_v,mean)$capacity_2010 

# rasterize 
ta_r = ta_capacity_v[!is.na(ta_capacity_v$vuln), "vuln"]
ta_r = st_rasterize(ta_r[1])
```


```{r extract traditional authorities without data by vuln, warning=FALSE}
ta_null <- ta_capacity_v[is.na(ta_capacity_v$vuln),]
#20 features

st_write(ta_null, 
         here("data", "derived", "public", "ta_null.shp"), 
         append=FALSE,
         quiet = TRUE)
```

```{r misc. map features}
#ea used to retrieve national parks (conservation areas) + lakes
ea = lhz_v %>%
  st_transform(3395) %>%  #transform to world mercator (jh: not sure if we need to transform to 3395 and back here?)
  summarize %>%  
  st_geometry %>%  #dissolve to one feature / one geometry
  st_intersection(st_geometry(st_transform(ta, 3395))) %>%   #intersect with traditional authorities to clip them
  st_transform(4326) %>%
  st_sf %>%   #make into new simple features data frame
  mutate(EA = case_when(
    grepl("Reserve", ta[["NAME_2"]]) | grepl("Park", ta[["NAME_2"]]) ~ "National Parks and Reserves",
    T ~ "Missing Data") # search and replace names anything with Reserve or Park in the name becomes National Parks and Reserves
  ) %>%
  rbind(lakes) %>%
  st_make_valid()
```

```{r 2010 adaptive capacity map}
# create map legend, starting with natural breaks intervals created earlier
map_2010legend <- c("#333333","#666666","#999999","#CCCCCC")  
names(map_2010legend) <- ta_int 
map_2010legend <- append(map_2010legend, c(
    "Missing Data" = "#FFC389",
    "National Parks and Reserves" = "#D9EABB",
    "Major Lakes of Malawi" = "lightblue"
  ))

# create the map
map_2010 = ggplot() +
  geom_sf(data = ea,
          aes(fill = EA),
          color = NA) +
  geom_sf(
    data = ta_capacity_v,
    aes(fill = capacity_2010_brks),
    color = "white",
    lwd = .2) + 
  scale_fill_manual(values = map_2010legend) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Adaptive Capacity Scores of\n222 Traditional Authorities in 2010") +
  theme_minimal() +
  theme(legend.title = element_blank())

map_2010
```

```{r find break & limit values for vulnerability map}
vuln_max <- max(final[[1]],na.rm = TRUE)
vuln_min <- min(final[[1]],na.rm = TRUE)
``` 

```{r vulnerability map}
clrs = mutate(
  ea,
  colors = case_when(
    EA == "Missing Data" ~ "#999999",
    EA == "National Parks and Reserves" ~ "#D9EABB",
    EA == "Major Lakes of Malawi" ~ "lightblue"
  )
)$colors

vuln_map = ggplot() +
  geom_sf(data = ea,
          fill = clrs,
          color = NA) +
  geom_stars(data = final) +
  scale_fill_gradient(
    low = "#FFFF75",
    high = "#CF4611",
    breaks = c(vuln_min, vuln_max),
    labels = c("Lower Vulnerability", "Higher Vulnerability"),
    na.value = "transparent",
    guide = "colourbar",
    limits = c(vuln_min, vuln_max)
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Malawi Vulnerability to Climate Change") +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

vuln_map
```

```{r saving fig 4 and 5 maps}

ggsave(
  here("results","figures","fig4rep_final.png"),
  plot = map_2010,
  width = 8.5,
  height = 11,
  units = "in"
)
ggsave(
  here("results","figures","fig5rep_final.png"),
  plot = vuln_map,
  width = 8.5,
  height = 11,
  units = "in"
)
```

```{r saving spatial data outputs}
results = here("data","derived","public","results.gpkg")

write_stars(ta_r, here("data","derived","public","ta_capacity.tif"))

write_sf(ta_capacity_v, results, "ta_capacity_v")

write_sf(lhz_v, results, "lhz")
```

```{R Sample Code for Comparing Discrete Choropleth Maps, warning=FALSE}
or_fig4 = # load original figure 4 data
  read_sf(here("data", "derived", "public", "ta_fig4_v.gpkg"), 
          layer="ta_fig4_v") %>% 
  # load ta_resilience layer from georeferencing geopackage
  st_drop_geometry() %>%
  # remove the geometry data because two geometries cannot be joined
  select(c(ID_2,capacity)) %>%  
  # select only the ID_2 and resilience columns
  na.omit()
  # remove records with null values

rp_fig4 = ta_capacity_v %>% # prepare our reproduction of figure 4 data
  select(c(ID_2,capacity_2010)) %>%  
  # select only the ID_2 and resilience columns
  # note: geometry columns are 'sticky' -- only way to remove is st_drop_geometry()
  na.omit() %>%
  # remove records with null values
  mutate(rp_ac = case_when(
  capacity_2010 <= ta_brks[2] ~ 1,
  capacity_2010 <= ta_brks[3] ~ 2,
  capacity_2010 <= ta_brks[4] ~ 3,
  capacity_2010 >  ta_brks[4] ~ 4
))
# code the capacity scores as integers, as we see them classified on the map. 
#ta_brks was the result of a Jenks classification, as noted on Malcomb et al's maps

fig4compare = inner_join(rp_fig4,or_fig4,by="ID_2") %>%  
  #inner join on field ID_2 keeps only matching records
  filter(rp_ac>0 & rp_ac<5 & capacity > 0 & capacity < 5)
  # keep only records with valid capacity scores

table(fig4compare$capacity,fig4compare$rp_ac)
# crosstabulation with frequencies

cor.test(fig4compare$capacity,fig4compare$rp_ac,method="spearman")
# Spearman's Rho correlation test

fig4compare = mutate(fig4compare, difference = rp_ac - capacity) 
# Calculate difference between the maps so that you can create a difference map
```
In order to compare the raster map produced with figure 5 from Malcomb et al (2014), figure 5 was georeferenced creating a ta_capacity.tif, which was then converted into polygons with the raster pixels to polygons tool. The authors used a color ramp of yellow to red in their raster map, so the best way to extract a linear relationship for comparison as we found was to add the blues and greens together in QGIS via zonal stats. After, the georeferenced TA's with color information were exported as a geopackge: georef_bg.gpkg and read into R for analysis.

```{R Sample Code for Comparing Continuous Raster Maps, warning=FALSE}
orfig5vect = 
  read_sf(here("data", "derived", "public", "georef_bg.gpkg"), 
          layer="georef_bg") %>%
  mutate(bg_mean = bmean + gmean)
# load original georeferenced figure 5 data

orfig5rast = st_rasterize(orfig5vect["bg_mean"], template=blank)
# convert mean of blue and green values into a raster using ta_final as a reference for raster
# extent, cell size, CRS, etc.

orfig5rast = orfig5rast %>% 
  mutate(or = 1-
           (bg_mean - min(orfig5rast[[1]], na.rm= TRUE)) /
           (max(orfig5rast[[1]], na.rm= TRUE) -
            min(orfig5rast[[1]], na.rm= TRUE)
        )
)  # or is Re-scaled from 0 to 1 with (value - min)/(max - min)
# it is also inverted, because higher blue values are less red

final = final %>% 
  mutate(rp =
           (capacity_2010 - min(final[[1]], na.rm= TRUE)) /
           (max(final[[1]], na.rm= TRUE) -
            min(final[[1]], na.rm= TRUE)
        )
)  # rp is Re-scaled from 0 to 1 with (value - min)/(max - min)

fig5comp = c( select(final,"rp"), select(orfig5rast,"or"))
# combine the original (or) fig 5 and reproduced (rp) fig 5

fig5comp = fig5comp %>% mutate( diff = rp - or )
# calculate difference between the original and reproduction,
# for purposes of mapping

fig5comppts = st_as_sf(fig5comp)
# convert raster to vector points to simplify plotting and correlation testing

plot(fig5comppts$or, fig5comppts$rp, xlab="Original Study", ylab="Reproduction")
title("Comparing Vulnerability Scores")
# create scatterplot of original results and reproduction results

cor.test(fig5comppts$or, fig5comppts$rp, method="spearman")
# Spearman's Rho correlation test

# Hint for mapping raster results: refer to the diff raster attribute
# in the fig5comp stars object like this: fig5comp["diff"]
```

```{r 2010 adaptive capacity difference map}
ac_diff_map = ggplot() +
  geom_sf(data = ea,
          aes(fill = EA),
          color = NA) +
  geom_sf(
    data = fig4compare,
    aes(fill = factor(difference)),
    color = "white",
    lwd = .2
  ) + scale_fill_manual(limits = c("-2","-1","0","1","Missing Data","Major Lakes of Malawi","National Parks and Reserves"),
    values = list(
      "Missing Data" = "#FFFFFF",
      "National Parks and Reserves" = "#D9EABB",
      "Major Lakes of Malawi" = "lightblue",
      "-2" = "#e66101",
      "-1" = "#fdb863",
      "0" = "#cccccc",
      "1" = "#b2abd2"
    )
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Fig. 4 Replication Comparison") +
  theme_minimal() +
  theme(legend.title = element_blank())

ac_diff_map
```

```{r find break & limit values for vulnerability difference map}
abs(max(fig5comp[[3]],na.rm = TRUE))
abs(min(fig5comp[[3]],na.rm = TRUE))
range <- max(abs(max(fig5comp[[3]],na.rm = TRUE)),abs(min(fig5comp[[3]],na.rm = TRUE)))
# takes the greatest value and makes it the range
``` 

```{r vulnerability difference map}
clrs = mutate(
  ea,
  colors = case_when(
    EA == "Missing Data" ~ "#999999",
    EA == "National Parks and Reserves" ~ "#D9EABB",
    EA == "Major Lakes of Malawi" ~ "lightblue"
  
  )
)$colors
vuln_diff_map = ggplot() +
  geom_sf(data = ea,
          fill = clrs,
          color = NA) +
  geom_stars(data = fig5comp["diff"]) +
  scale_fill_gradient2(
    low = "#e9a3c9",
    high = "#beaed4",
    breaks = c(-range,range),
    labels = c("Negative Difference", "Positive Difference"),
    na.value = "transparent",
    guide = "colourbar",
    limits = c(-range,range) #you want centered around zero, so make larger # the ends
  ) +
  scale_x_continuous(breaks = c(33,34,35,36)) +
  labs(title = "Fig. 5 Replication Comparison") +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )
vuln_diff_map
```

```{r saving maps}
ggsave(
  here("results","figures","fig4comp_final.png"),
  plot = ac_diff_map,
  width = 8.5,
  height = 11,
  units = "in"
)
ggsave(
  here("results","figures","fig5comp_final.png"),
  plot = vuln_diff_map,
  width = 8.5,
  height = 11,
  units = "in"
)
```

```{r exporting comparison as geotiff}
write_stars(fig5comp, here("data", "derived", "public", "fig5diff.tif"), layer = "diff")
write_stars(fig5comp, here("data", "derived", "public", "fig5or.tif"), layer = "or")
write_stars(fig5comp, here("data", "derived", "public", "fig5rp.tif"), layer = "rp")
```